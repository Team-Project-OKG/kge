import: [packed_lstm_lookup_embedder]                                         #!!! adjust if model is changed

# general settings for the hyperparameter optimization job
job.type: search
search.type: grid
valid.metric: mean_reciprocal_rank_filtered


# settings for the dataset to use
dataset:
  type: olp
  name: olpbench_small_bert

# settings for ComplEx and the respective embedders
model: complex

complex:
  entity_embedder.type: packed_lstm_lookup_embedder                           #!!! adjust if model is changed
  relation_embedder.type: packed_lstm_lookup_embedder                         #!!! adjust if model is changed

packed_lstm_lookup_embedder:                                                  #!!! adjust if model is changed (incl. parameters of the model)
  initialize: xavier_uniform_ # is Glorot initialization
  token_embedding_model:
    use: True
    name: prajjwal1/bert-mini
    precache: 5
  pretrained:
    use: False
    file:
      name: bert-tokens
      type: txt
  dim: 256
  num_layers: 2

random_seed:
  # Seed used to initialize each of the PRNGs below in case they do not have
  # their own seed specified. The actual seed used computed from the value given
  # here and the name of the PRNG (e.g., python, torch, ...). If -1, disable
  # default seeding.
  default: 1

  python: 1
  torch: 1
  numpy: 1
  numba: 1


# settings for the training job of each hyperparameter combination
train:
  type: negative_sampling
  max_epochs: 2
  batch_size: 4096
  subbatch_auto_tune: True
  optimizer: Adagrad
#  lr_scheduler: ReduceLROnPlateau
#  lr_scheduler_args:
#    mode: max
#    patience: 4'


# settings for negative sampling
# use number of replacements equal to the batch size to approximate Samuel's negative sampling algorithm
# num_samples describes the length of individual samples, not the number of samples. e.g. num_sample: 4 -> [rand, rand, rand, rand]; num_sample:3 -> [rand, rand, rand]
#!!! look into how to reproduce Samuel's negative sampling algorithm
negative_sampling:
  shared: True
  with_replacement: False
  implementation: batch
  samples_within_batch: True
  num_samples: # can be ignored if samples_within_batch is True
    s: 100
    #p: 0          # -1 means: same as s
    #o: -1

valid:
  every: 1


# settings for the evaluation job
eval:
  type: olp_entity_ranking
  batch_size: 5000
