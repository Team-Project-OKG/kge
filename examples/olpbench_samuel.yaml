import: [unigram_lookup_embedder]                                         #!!! adjust if model is changed

# general settings for the hyperparameter optimization job
job.type: search
search.type: grid
valid.metric: mean_reciprocal_rank_filtered

grid_search:
  parameters:
    train.optimizer.default.args:
      lr: [0.05, 0.1, 0.2]
      weight_decay: [1e-6, 1e-10]
    unigram_lookup_embedder:                                              #!!! adjust if model is changed
      dim: [256, 512]
      dropout: [0., 0.1]


# settings for the dataset to use
dataset:
  name: olpbench
  files.valid.filename: validation_linked.del


# settings for ComplEx and the respective embedders
model: complex

complex:
  entity_embedder.type: unigram_lookup_embedder                           #!!! adjust if model is changed
  relation_embedder.type: unigram_lookup_embedder                         #!!! adjust if model is changed

unigram_lookup_embedder:                                                  #!!! adjust if model is changed
  pooling: "max"
  initialize: xavier_uniform_ # Glorot initialization


# settings for the training job of each hyperparameter combination
train:
  type: negative_sampling
  max_epochs: 10
  batch_size: 4096
  subbatch_auto_tune: True
  optimizer: Adagrad
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_args:
    mode: max
    patience: 4


# settings for negative sampling
# use number of replacements equal to the batch size to approximate Samuel's negative sampling algorithm
negative_sampling:
  implementation: batch
  num_samples:
    s: 4096
    p: 0          # -1 means: same as s
    o: -1


# settings for the evaluation job
eval:
  type: olp_entity_ranking
  batch_size: 500
