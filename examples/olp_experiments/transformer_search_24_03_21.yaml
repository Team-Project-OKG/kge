import: [transformer_lookup_embedder]                                         #!!! adjust if model is changed

# general settings for the hyperparameter optimization job
job.type: search
search.type: ax
valid.metric: mean_reciprocal_rank_filtered

ax_search:
  num_trials: 10
  num_sobol_trials: 10
  parameters:
    - name: train.optimizer.default.args.weight_decay
      type: range
      bounds: [0.0000000001, 0.000001]
    - name: transformer_lookup_embedder.dim
      type: choice
      values: [256, 512]
    - name: transformer_lookup_embedder.num_layers
      type: choice
      bounds: [3, 4]
    - name: transformer_lookup_embedder.pooling
      type: choice
      bounds: ["mean", "cls"]
    - name: transformer_lookup_embedder.warmup
      type: range
      bounds: [4000, 8000]
    - name: transformer_lookup_embedder.transformer_dropout
      type: range
      bounds: [0.0, 0.1]





# settings for the dataset to use
dataset:
  type: olp
  name: olpbench

# settings for ComplEx and the respective embedders
model: complex

complex:
  entity_embedder.type: transformer_lookup_embedder                           #!!! adjust if model is changed
  relation_embedder.type: transformer_lookup_embedder                         #!!! adjust if model is changed

transformer_lookup_embedder:                                                  #!!! adjust if model is changed (incl. parameters of the model)
  cut_padding_in_batch: True
  set_padding_embeddings_to_0: True
  bin_within_batch: True
  bin_size: 1000
  initialize: xavier_uniform_ # is Glorot initialization
  nhead: 8
  dim_ff: 2048
  custom_lr: True
  dropout: 0
# settings for the training job of each hyperparameter combination
train:
  type: negative_sampling
  max_epochs: 5
  batch_size: 2048
  subbatch_auto_tune: True
  optimizer:
    +++: +++
    default:
      args:
        +++: +++
        eps: 1e-9
        lr: 0
      type: Adam
#  lr_scheduler: ReduceLROnPlateau
#  lr_scheduler_args:
#    mode: max
#    patience: 4'


# settings for negative sampling
# use number of replacements equal to the batch size to approximate Samuel's negative sampling algorithm
# num_samples describes the length of individual samples, not the number of samples. e.g. num_sample: 4 -> [rand, rand, rand, rand]; num_sample:3 -> [rand, rand, rand]
#!!! look into how to reproduce Samuel's negative sampling algorithm
negative_sampling:
  shared: True
  with_replacement: False
  implementation: batch
  samples_within_batch: True
  #num_samples:
  #  s: 8192
  #  p: 0          # -1 means: same as s
  #  o: -1


# settings for the evaluation job
eval:
  type: olp_entity_ranking
  batch_size: 500
