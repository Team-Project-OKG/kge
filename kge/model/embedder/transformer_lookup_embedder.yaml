# Stores explicitly an embedding for each object in a lookup table. See
# https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding
transformer_lookup_embedder:
  class_name: TransformerLookupEmbedder

  # parameters specific to Transformer Lookup Embedder

  # general settings for mention embedders (see mention_embedder.yaml for explanations)
  requires_start_and_end_token: False

  bin_within_batch: False
  bin_size: 0

  pretrained:
    use: False
    file:
      name: glove.840B.300d_word2vec
      type: txt
    oov_tactic: 'random'
    freeze: False
    use_pickle: True

  # settings for lookup embedders (see lookup_embedder.yaml for explanations)
  dim: 128
  nhead: 8
  num_layers: 6
  initialize: normal_
  initialize_args:
    +++: +++
  pretrain:
      model_filename: ""
      ensure_all: False
  dropout: 0.
  normalize:
    p: -1.
  regularize: 'lp'
  regularize_weight: 0.0
  regularize_args:
    weighted: False
    p: 2
    +++: +++
  sparse: False
  round_dim_to: []